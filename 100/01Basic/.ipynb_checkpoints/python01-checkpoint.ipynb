{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47e4be2-5063-402e-9a19-e48eb4528b38",
   "metadata": {},
   "source": [
    "### 1. 네이버 뉴스에서 '디지털 마케팅'키워드로 검색한 뉴스 제목 10개를 수집하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f90a28a-e464-40d7-92be-587f80bede62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 한컴위드, 다날과 차세대 디지털 금융 서비스 시장 공동 공략\n",
      "2. JT저축은행-한국폴리텍대학, 디지털 역량 강화 위한 챗GPT 교육\n",
      "3. 조선대, 인도네시아 에어랑가대학 대상 치과기술 마케팅 연수 개최\n",
      "4. SOOP, 2Q 영업익 300억·9.9%↓…'마케팅·인건비' 상승 영향\n",
      "5. 롯데·신라免, 타겟 마케팅으로 부진 속 돌파구 찾는다\n",
      "6. 국민체육진흥공단, '전국 대학생 스포츠 마케팅 경진 대회' 개최\n",
      "7. 진화하는 은행 캐릭터 마케팅…신한은행 \"금융 여정 동행 경험 심는다\"\n",
      "8. 다날·한컴위드, 스테이블코인 전자금융 사업 본격화 …\"시장 최적화 디...\n",
      "9. [Biz-inside,China] 쑥쑥 크는 中 전자상거래, AI로 무장하다…상담·마케...\n",
      "10. 정읍시, 지황 농산물 가공식품 온라인 마케팅 강화교육 수료\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup # 찾아온 문서를 이해할 수 있도록 변경\n",
    "\n",
    "query = \"디지털 마케팅\"\n",
    "url = f\"https://search.naver.com/search.naver?where=news&query={query}\" # 문자열로 찾아올거니까 f스트링으로 \n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "titles = soup.select(\"a.ox1N67gcMkHhMh7hbfHi.VZxw34rcBHTWHgERxv0b\") # 동일한 요소를 찾아서 리스트 형태로 반환\n",
    "\n",
    "for i, title in enumerate(titles[:10], 1) :\n",
    "    print(f\"{i}. {title.text.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c57cd5-b4aa-42fc-bdad-fd61a2cb3c03",
   "metadata": {},
   "source": [
    "### 2. 다음 뉴스에서 IT 섹션의 기사 제목과 링크를 수집하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54479f1e-d0a1-48a2-9f3e-ebaff0c8ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 수천만 개 사내문서도 ‘뚝딱’…日서 난리 난 AI가 국내산? '시간이 없는데 언제 일일히 사내 문서를 찾아보지.' 이 같이 대다수 직장인들이 하는 업무의 비효율성 문제를 해결한 기업이 있다. 코딩 없이 AI를 활용할 수 있게 만든 ‘노코드 AI 플랫폼’을 전면에 앞세우면서다. 이 기업은 자체 기술로 일본 기업용 AI 시장을 단숨에 장악하고 있다. 엔터프라이즈 특화 생성형 AI 솔루션 기업 올거나이즈는 자사의 LLM 한국경제 2분 전 - https://v.daum.net/v/20250730141204652\n",
      "2. 하반기 줄잇는 신작게임에 'MMORPG' 부활…\"사활 걸었다\" 머니투데이 2분 전 - https://v.daum.net/v/20250730141146624\n",
      "3. 뜨거운 감자 '게임 질병코드'… 문체-복지, 엇갈린 답변에 대립각 재점화 전자신문 3분 전 - https://v.daum.net/v/20250730141104596\n",
      "4. AI로 디지털 자신감 키운다…과학동아AiR 수업에서 몰입 효과 확인 동아사이언스 6분 전 - https://v.daum.net/v/20250730140804479\n",
      "5. 네이처 “中 인재 유치 정책, 연구 능력 높였지만 내부 균열도 심화” 조선비즈 11분 전 - https://v.daum.net/v/20250730140257231\n",
      "6. 폭염·열대야에도 생체 시계 고장 없는 이유…[달콤한 사이언스] 서울신문 12분 전 - https://v.daum.net/v/20250730140204159\n",
      "7. [人사이트] 전명준 KT 데이터서비스담당 “디도스 공격 대형화 추세…클린존으로 기업 보안관될 것” 전자신문 21분 전 - https://v.daum.net/v/20250730135300778\n",
      "8. 냅킨에 적은 아이디어가 5년 뒤 논문으로…\"수학연구의 시작은 대화\" 동아사이언스 26분 전 - https://v.daum.net/v/20250730134747596\n",
      "9. 로아 요아정 \"날도 더우니 한 번쯤 먹어볼 만 하다\" 게임톡 49분 전 - https://v.daum.net/v/20250730132454565\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://news.daum.net/tech\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\" # 모든 사이트가 네이버처럼 한글을 제공해주는 것은 아님. 상형문자로 나오는 것을 한글로 바꾼다는 개념\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "articles = soup.select(\"ul.list_newsheadline2 li a.item_newsheadline2\")\n",
    "# print(articles) # 상형문자가 나옴\n",
    "for i, article in enumerate(articles, 1) :\n",
    "    title = article.text.strip()\n",
    "    link = article[\"href\"]\n",
    "    print(f\"{i}. {title} - {link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c437c-8b61-411e-80a8-183676fdffd0",
   "metadata": {},
   "source": [
    "### 3. yes24의 경제 베스트셀러 1~10위 도서 제목과 저자를 수집하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d3cc5c2-0179-4cd6-8ae1-986220adb16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 자본주의 - EBS 〈자본주의〉제작팀, 정지은, 고희정 저/EBS MEDIA 기획\n",
      "2. 생각에 관한 생각 - 대니얼 카너먼 저/이창신 역\n",
      "3. 더 그레이트 비트코인 - 오태민 저\n",
      "4. 부의 추월차선 (10주년 스페셜 에디션) - 엠제이 드마코 저/신소영 역\n",
      "5. 레버리지 - 롭 무어 저/김유미 역\n",
      "6. 달러는 왜 비트코인을 싫어하는가 - 사이페딘 아모스 저/위대선 역\n",
      "7. 넛지: 파이널 에디션 - 리처드 탈러, 캐스 선스타인 저/이경식 역/최정규 감수\n",
      "8. 시대예보: 핵개인의 시대 - 송길영 저\n",
      "9. 일할 사람이 사라진다 - 이철희 저\n",
      "10. 경제신문이 말하지 않는 경제 이야기 - 임주영 저\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.yes24.com/product/category/steadyseller?categoryNumber=001001025007\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "books = soup.select(\"ul#yesBestList > li\")\n",
    "\n",
    "for i, book in enumerate(books[:10], 1) :\n",
    "    title_tag = book.select_one(\"div.info_row.info_name a.gd_name\")\n",
    "    author_tag = book.select_one(\"span.authPub.info_auth\")\n",
    "    \n",
    "    if title_tag and author_tag : # and연산자 : 좌항과 우항 값이 모두 참이어야 실행\n",
    "        title = title_tag.text.strip()\n",
    "        author = author_tag.text.strip()\n",
    "        print(f\"{i}. {title} - {author}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e5228-932e-4e04-8588-3778b1d92b1c",
   "metadata": {},
   "source": [
    "### 4. 기상청 날씨 페이지에서 오늘의 전국 날씨 요약을 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4316d780-90cf-4948-a4dd-5ed2e96bca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘의 전국 날씨 요약 :\n",
      "□  (종합) 당분간 무더위와 열대야 주의, 전남해안과 경남남해안, 제주도해안 너울 유의\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.weather.go.kr/w/weather/forecast/short-term.do\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "summery_tag = soup.select_one(\"div.cmp-view-content > p.summary > span.depth_1\")\n",
    "\n",
    "if summery_tag :\n",
    "    print(\"오늘의 전국 날씨 요약 :\")\n",
    "    print(summery_tag.text.strip())\n",
    "else :\n",
    "    print(\"날씨 요약 정보를 찾을 수 없습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f78a45-06f2-4ceb-bd49-9ff2fae4d899",
   "metadata": {},
   "source": [
    "### 5. 잡코리아에서 '데이터 분석가' 직무 공고 제목 20개를 수집하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fc5cbed-fd79-425d-a697-3b3e77dd6dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터 분석가 (경력)\n",
      "2. 데이터 분석가\n",
      "3. [CVS] 데이터 분석가(Business Analyst)\n",
      "4. [쿡앱스] 게임 데이터 분석가 모집\n",
      "5. [기어세컨드] 데이터 분석가 채용\n",
      "6. 데이터 애널리스트 / 데이터분석 전문가 / 통계 전문가 / Data Analyst (통\n",
      "7. Data Analyst (데이터 분석가)\n",
      "8. [CVS] 데이터 분석가 1년 인턴 (Business Analyst Intern)\n",
      "9. [인텔리전스랩스그룹] 데이터 분석가 (인게임 로그 및 비즈니스 인사이트 분석)\n",
      "10. 데이터 분석가(신입/경력)\n",
      "11. 공공데이터 품질 관리와 진단, 데이터 분석가\n",
      "12. [다우키움 계열사] 데이터 분석가 (경력)\n",
      "13. [통계팀] 데이터 분석가 모집\n",
      "14. [커머스플랫폼팀] 데이터 분석 전문가 (Senior Data Analyst) 모집\n",
      "15. [디저트39] 데이터 분석가(Data Analyst)/데이터 분석 엔지니어 팀장급\n",
      "16. 데이터분석가 구인\n",
      "17. [어니컴(주)] 데이터분석가 신입/경력 모집\n",
      "18. [(중급이상/ 경력직)] 빅데이터 전문가를 모십니다\n",
      "19. 데이터분석가 채용(경력)\n",
      "20. [리비바이오] 데이터분석가\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "query = \"데이터 분석가\"\n",
    "url = f\"https://www.jobkorea.co.kr/Search/?stext={query}\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.encoding = \"utf-8\"\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 내꺼\n",
    "# jobs = soup.select(\"div.styles_flex_none__dk46tsah a.sn28bt0\")\n",
    "# # print(jobs)\n",
    "\n",
    "# for i, job in enumerate(jobs[:21], 1) :\n",
    "#     print(f\"{i}. {job.text.strip()}\")\n",
    "\n",
    "# 선생님꺼\n",
    "titles = soup.select(\"div.styles_mb_space8__dk46ts1p a.sn28bt0\")\n",
    "\n",
    "for i, title_tag in enumerate(titles[:20], 1) :\n",
    "    print(f\"{i}. {title_tag.text.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2cd7b2-e247-45a0-bfd7-c3947591adab",
   "metadata": {},
   "source": [
    "### 6. 잡코리아에서 '데이터 분석가' 직무 공고 제목 20개를 수집하세요.\n",
    "- 셀레니움 코드로 크롤링 하기\n",
    "- 6개 페이지 > 서울지역 > 경력 1~3년차만 크롤링해오기\n",
    "- 엑셀로 출력 (*해당 공고 타이틀과 지원할 수 있는 url 링크)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5be1c292-d9dd-4fc0-a426-e215f687bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3bcf424f-de0e-4f32-a200-12f535c8376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엑셀 저장 완료\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import urllib.parse # 사전적 인코딩\n",
    "import pandas as pd # 데이터 전처리 -> 실제 사용자에게 보여주기 전에 처리한다. pandas : 수집한 데이터를 테이블화 하는 것에 압도적으로 좋음.\n",
    "\n",
    "\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--window-size=1920x1080\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--User-Agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\")\n",
    "options.add_argument(\"--lang=ko_KR\")\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options = options)\n",
    "\n",
    "query = \"데이터 분석가\"\n",
    "encoded_query = urllib.parse.quote(query)\n",
    "\n",
    "max_pages = 6\n",
    "\n",
    "results = []\n",
    "\n",
    "for page in range(1, max_pages + 1) :\n",
    "    url = f\"https://www.jobkorea.co.kr/Search?stext={encoded_query}&Page_No={page}&local=I000&tabType=recruit&careerType=1\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    job_posts = driver.find_elements(By.CSS_SELECTOR, \"div.styles_mb_space8__dk46ts1p\")\n",
    "    for post in job_posts :\n",
    "        try :\n",
    "            title_elem = post.find_element(By. CSS_SELECTOR, \"a.sn28bt0\")\n",
    "            title = title_elem.text.strip()\n",
    "            link = title_elem.get_attribute(\"href\")\n",
    "            results.append({\n",
    "                \"제목\" : title,\n",
    "                \"지원링크\" : link\n",
    "            })\n",
    "        except :\n",
    "            continue\n",
    "            \n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"잡코리아_데이터분석가_서울_신입_3페이지.xlsx\", index=False)\n",
    "print(\"엑셀 저장 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
